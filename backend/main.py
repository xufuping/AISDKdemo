"""
FastAPI åç«¯ - é˜¶æ®µ2ï¼šé›†æˆ RAG
ç›®æ ‡ï¼šä»çŸ¥è¯†åº“æ£€ç´¢ç›¸å…³ä¿¡æ¯ï¼Œç”ŸæˆåŸºäºçŸ¥è¯†åº“çš„å›ç­”
"""

import os
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import List, Optional
from dotenv import load_dotenv
import google.generativeai as genai
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_chroma import Chroma

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# åˆå§‹åŒ– FastAPI
app = FastAPI(
    title="åŒ»å­¦çŸ¥è¯†é—®ç­”ç³»ç»Ÿ",
    description="åŸºäº RAG çš„å‚ç›´é¢†åŸŸé—®ç­”æœºå™¨äºº",
    version="0.2.0"
)

# é…ç½® CORSï¼ˆå…è®¸å‰ç«¯è®¿é—®ï¼‰
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # å¼€å‘ç¯å¢ƒå…è®¸æ‰€æœ‰æº
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# åˆå§‹åŒ– Google AI
api_key = os.getenv("GOOGLE_AI_API_KEY")
if not api_key:
    raise ValueError("âŒ è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® GOOGLE_AI_API_KEY")

genai.configure(api_key=api_key)

# ==========================================
# åˆå§‹åŒ–å‘é‡æ•°æ®åº“å’Œæ£€ç´¢å™¨
# ==========================================
VECTOR_STORE_DIR = "./vector_store"

print("=" * 60)
print("ğŸš€ åˆå§‹åŒ–åŒ»å­¦çŸ¥è¯†é—®ç­”ç³»ç»Ÿ")
print("=" * 60)

# åˆå§‹åŒ– Embeddingsï¼ˆä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼‰
try:
    from langchain_huggingface import HuggingFaceEmbeddings
    
    embeddings = HuggingFaceEmbeddings(
        model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True}
    )
    print("âœ… æœ¬åœ° Embedding æ¨¡å‹åŠ è½½æˆåŠŸ")
except Exception as e:
    print(f"âŒ Embedding æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    embeddings = None

# åˆå§‹åŒ–å‘é‡æ•°æ®åº“
vectorstore = None
retriever = None

if os.path.exists(VECTOR_STORE_DIR) and embeddings:
    try:
        vectorstore = Chroma(
            persist_directory=VECTOR_STORE_DIR,
            embedding_function=embeddings,
            collection_name="medical_knowledge"
        )
        
        # åˆ›å»ºæ£€ç´¢å™¨ï¼ˆæ¯æ¬¡æ£€ç´¢è¿”å›å‰3ä¸ªæœ€ç›¸å…³çš„æ–‡æ¡£å—ï¼‰
        retriever = vectorstore.as_retriever(
            search_type="similarity",
            search_kwargs={"k": 3}
        )
        
        print(f"âœ… å‘é‡æ•°æ®åº“åŠ è½½æˆåŠŸ")
        print(f"ğŸ“ çŸ¥è¯†åº“ä½ç½®: {VECTOR_STORE_DIR}")
        
        # æµ‹è¯•æ£€ç´¢
        test_results = retriever.invoke("é«˜è¡€å‹")
        print(f"ğŸ§ª çŸ¥è¯†åº“æµ‹è¯•æˆåŠŸï¼Œå…±æœ‰ {len(test_results)} ä¸ªæ–‡æ¡£å—")
        
    except Exception as e:
        print(f"âš ï¸ å‘é‡æ•°æ®åº“åŠ è½½å¤±è´¥: {e}")
        print("ğŸ’¡ ç³»ç»Ÿå°†ä½¿ç”¨é€šç”¨é—®ç­”æ¨¡å¼ï¼ˆä¸ä½¿ç”¨çŸ¥è¯†åº“ï¼‰")
        retriever = None
else:
    if not os.path.exists(VECTOR_STORE_DIR):
        print(f"âš ï¸ æœªæ‰¾åˆ°å‘é‡æ•°æ®åº“ç›®å½•: {VECTOR_STORE_DIR}")
        print("ğŸ’¡ è¯·å…ˆè¿è¡Œ: python load_documents.py")
    print("ğŸ’¡ ç³»ç»Ÿå°†ä½¿ç”¨é€šç”¨é—®ç­”æ¨¡å¼ï¼ˆä¸ä½¿ç”¨çŸ¥è¯†åº“ï¼‰")

print("=" * 60)

# ==========================================
# æ•°æ®æ¨¡å‹
# ==========================================
class Message(BaseModel):
    """å•æ¡æ¶ˆæ¯"""
    role: str  # "user" æˆ– "assistant"
    content: str

class ChatRequest(BaseModel):
    """èŠå¤©è¯·æ±‚"""
    messages: List[Message]

# ==========================================
# æ ¸å¿ƒåŠŸèƒ½ï¼šRAG æ£€ç´¢å’Œç”Ÿæˆ
# ==========================================

def retrieve_knowledge(query: str) -> tuple[str, List[str]]:
    """
    ä»çŸ¥è¯†åº“æ£€ç´¢ç›¸å…³ä¿¡æ¯
    
    è¿”å›:
        context: æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡å†…å®¹
        sources: æ¥æºæ–‡ä»¶åˆ—è¡¨
    """
    if not retriever:
        return "", []
    
    try:
        # æ£€ç´¢ç›¸å…³æ–‡æ¡£
        docs = retriever.invoke(query)
        
        if not docs:
            return "", []
        
        # æå–å†…å®¹å’Œæ¥æº
        context_parts = []
        sources = []
        
        for i, doc in enumerate(docs, 1):
            # è·å–æ–‡ä»¶å
            source = os.path.basename(doc.metadata.get("source", "æœªçŸ¥æ¥æº"))
            sources.append(source)
            
            # æ„å»ºä¸Šä¸‹æ–‡
            context_parts.append(f"[æ–‡æ¡£{i}ï¼š{source}]\n{doc.page_content}")
        
        context = "\n\n".join(context_parts)
        
        print(f"ğŸ” æ£€ç´¢åˆ° {len(docs)} ä¸ªç›¸å…³æ–‡æ¡£å—")
        for source in set(sources):
            print(f"   ğŸ“„ {source}")
        
        return context, sources
        
    except Exception as e:
        print(f"âš ï¸ æ£€ç´¢å¤±è´¥: {e}")
        return "", []

def build_rag_prompt(user_query: str, context: str) -> str:
    """
    æ„å»º RAG æç¤ºè¯
    
    å°†æ£€ç´¢åˆ°çš„çŸ¥è¯†åº“å†…å®¹å’Œç”¨æˆ·é—®é¢˜ç»„åˆæˆæç¤ºè¯
    """
    if context:
        # æœ‰çŸ¥è¯†åº“å†…å®¹ï¼šä½¿ç”¨ RAG æ¨¡å¼
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŒ»å­¦çŸ¥è¯†é—®ç­”åŠ©æ‰‹ã€‚è¯·åŸºäºä»¥ä¸‹çŸ¥è¯†åº“å†…å®¹å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

ã€çŸ¥è¯†åº“å†…å®¹ã€‘
{context}

ã€ç”¨æˆ·é—®é¢˜ã€‘
{user_query}

ã€å›ç­”è¦æ±‚ã€‘
1. ä¼˜å…ˆä½¿ç”¨çŸ¥è¯†åº“ä¸­çš„ä¿¡æ¯å›ç­”
2. å›ç­”è¦å‡†ç¡®ã€ä¸“ä¸šã€æ˜“æ‡‚
3. å¦‚æœçŸ¥è¯†åº“ä¸­æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·åœ¨å›ç­”æœ«å°¾æ³¨æ˜ä¿¡æ¯æ¥æº
4. å¦‚æœçŸ¥è¯†åº“ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œå¯ä»¥ä½¿ç”¨ä½ çš„é€šç”¨çŸ¥è¯†å›ç­”ï¼Œä½†è¦è¯´æ˜è¿™ä¸æ˜¯æ¥è‡ªçŸ¥è¯†åº“
5. å›ç­”è¦ç®€æ´æ˜äº†ï¼Œåˆ†ç‚¹åˆ—å‡ºå…³é”®ä¿¡æ¯

è¯·å›ç­”ï¼š"""
    else:
        # æ²¡æœ‰çŸ¥è¯†åº“å†…å®¹ï¼šä½¿ç”¨é€šç”¨æ¨¡å¼
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŒ»å­¦çŸ¥è¯†é—®ç­”åŠ©æ‰‹ã€‚è¯·å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

ã€ç”¨æˆ·é—®é¢˜ã€‘
{user_query}

ã€å›ç­”è¦æ±‚ã€‘
1. å›ç­”è¦å‡†ç¡®ã€ä¸“ä¸šã€æ˜“æ‡‚
2. å›ç­”è¦ç®€æ´æ˜äº†ï¼Œåˆ†ç‚¹åˆ—å‡ºå…³é”®ä¿¡æ¯
3. å¦‚æœæ¶‰åŠåŒ»ç–—å»ºè®®ï¼Œæé†’ç”¨æˆ·å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿ

è¯·å›ç­”ï¼š"""
    
    return prompt

async def generate_stream_with_rag(messages: List[Message]):
    """
    ç”Ÿæˆæµå¼å“åº”ï¼ˆé˜¶æ®µ2ï¼šé›†æˆ RAGï¼‰
    """
    try:
        # è·å–æœ€æ–°çš„ç”¨æˆ·æ¶ˆæ¯
        user_message = messages[-1].content
        
        print(f"\nğŸ“¨ æ”¶åˆ°ç”¨æˆ·æ¶ˆæ¯: {user_message[:50]}...")
        
        # æ­¥éª¤1ï¼šæ£€ç´¢çŸ¥è¯†åº“
        context, sources = retrieve_knowledge(user_message)
        
        # æ­¥éª¤2ï¼šæ„å»ºæç¤ºè¯
        rag_prompt = build_rag_prompt(user_message, context)
        
        # æ­¥éª¤3ï¼šè·å– Gemini æ¨¡å‹
        model = genai.GenerativeModel('gemini-2.5-flash')
        
        # æ­¥éª¤4ï¼šæ„å»ºå¯¹è¯å†å²ï¼ˆä¸åŒ…æ‹¬å½“å‰é—®é¢˜ï¼Œå› ä¸ºå·²ç»åœ¨ rag_prompt ä¸­ï¼‰
        chat_history = []
        for msg in messages[:-1]:
            chat_history.append({
                "role": "user" if msg.role == "user" else "model",
                "parts": [msg.content]
            })
        
        # æ­¥éª¤5ï¼šåˆ›å»ºå¯¹è¯å¹¶ç”Ÿæˆå“åº”
        chat = model.start_chat(history=chat_history)
        response = chat.send_message(rag_prompt, stream=True)
        
        # æ­¥éª¤6ï¼šæµå¼è¾“å‡º
        for chunk in response:
            if chunk.text:
                yield chunk.text
        
        # æ­¥éª¤7ï¼šå¦‚æœæœ‰æ¥æºï¼Œåœ¨å›ç­”æœ«å°¾æ·»åŠ æ¥æºä¿¡æ¯
        if sources:
            unique_sources = list(set(sources))
            sources_text = "\n\n---\nğŸ“š **ä¿¡æ¯æ¥æº**ï¼š\n"
            for source in unique_sources:
                sources_text += f"- {source}\n"
            yield sources_text
        
        print("âœ… å“åº”ç”Ÿæˆå®Œæˆ")
        
    except Exception as e:
        error_msg = f"ç”Ÿæˆå“åº”æ—¶å‡ºé”™: {str(e)}"
        print(f"âŒ {error_msg}")
        yield f"\n\n[é”™è¯¯: {error_msg}]"

# ==========================================
# API è·¯ç”±
# ==========================================

@app.get("/")
async def root():
    """å¥åº·æ£€æŸ¥"""
    has_knowledge_base = retriever is not None
    
    return {
        "status": "ok",
        "message": "åŒ»å­¦çŸ¥è¯†é—®ç­”ç³»ç»Ÿ API",
        "version": "0.2.0",
        "stage": "é˜¶æ®µ2ï¼šRAG é›†æˆ",
        "knowledge_base_loaded": has_knowledge_base,
        "features": {
            "rag": has_knowledge_base,
            "general_qa": True
        }
    }

@app.post("/api/chat")
async def chat_endpoint(request: ChatRequest):
    """
    èŠå¤©æ¥å£ï¼ˆæµå¼å“åº” + RAGï¼‰
    """
    try:
        if not request.messages:
            raise HTTPException(status_code=400, detail="æ¶ˆæ¯åˆ—è¡¨ä¸èƒ½ä¸ºç©º")
        
        # è¿”å›æµå¼å“åº”
        return StreamingResponse(
            generate_stream_with_rag(request.messages),
            media_type="text/plain",
            headers={
                "Cache-Control": "no-cache",
                "X-Accel-Buffering": "no"
            }
        )
        
    except Exception as e:
        print(f"âŒ èŠå¤©æ¥å£é”™è¯¯: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ï¼ˆè¯¦ç»†ä¿¡æ¯ï¼‰"""
    return {
        "status": "healthy",
        "google_ai_configured": bool(os.getenv("GOOGLE_AI_API_KEY")),
        "knowledge_base_loaded": retriever is not None,
        "vector_store_path": VECTOR_STORE_DIR,
        "vector_store_exists": os.path.exists(VECTOR_STORE_DIR)
    }

@app.post("/api/search")
async def search_knowledge(query: str):
    """
    æµ‹è¯•æ¥å£ï¼šç›´æ¥æœç´¢çŸ¥è¯†åº“
    """
    if not retriever:
        raise HTTPException(status_code=503, detail="çŸ¥è¯†åº“æœªåŠ è½½")
    
    try:
        docs = retriever.invoke(query)
        
        results = []
        for doc in docs:
            results.append({
                "source": os.path.basename(doc.metadata.get("source", "æœªçŸ¥")),
                "content": doc.page_content[:200] + "...",
                "metadata": doc.metadata
            })
        
        return {
            "query": query,
            "results_count": len(results),
            "results": results
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ==========================================
# å¯åŠ¨æœåŠ¡
# ==========================================

if __name__ == "__main__":
    import uvicorn
    
    host = os.getenv("BACKEND_HOST", "0.0.0.0")
    port = int(os.getenv("BACKEND_PORT", 8000))
    
    print(f"""
    ==========================================
    ğŸš€ å¯åŠ¨åŒ»å­¦çŸ¥è¯†é—®ç­”ç³»ç»Ÿåç«¯
    ==========================================
    ğŸ“ åœ°å€: http://{host}:{port}
    ğŸ“– APIæ–‡æ¡£: http://{host}:{port}/docs
    ğŸ”§ é˜¶æ®µ: é˜¶æ®µ2 - RAG é›†æˆ
    ğŸ“š çŸ¥è¯†åº“: {'å·²åŠ è½½ âœ…' if retriever else 'æœªåŠ è½½ âš ï¸'}
    ==========================================
    """)
    
    uvicorn.run(
        "main:app",
        host=host,
        port=port,
        reload=True,
        log_level="info"
    )